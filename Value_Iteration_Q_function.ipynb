{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Value-Iteration-Q-function.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfC6UgZEgrV+8RdNts/Cq1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jalapinho1/Deep-Reinforcement-Learning-Explained/blob/main/Value_Iteration_Q_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3P9a9Q6mjhD"
      },
      "source": [
        "# **Value Iteration for Q-function**\n",
        "\n",
        "We will review the Q-function and present the Value Iteration method that learns the values of the actions to create a policy.\n",
        "\n",
        "As we will see later in this post, Q-values are much **more convenient** in practice, as for the Agent, it’s much simpler to make decisions about actions based on Q-values than on V-values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFd6YqV-nuIJ"
      },
      "source": [
        "Based on the previous Value Iteration method implementation for V-function, in the case of action values, only minor modifications to the preceding code are required. The most obvious change is to our **value table**. In the previous case, we kept the value of the state, so the key in the dictionary was just a state. Now we need to store **values of the Q-function**, which has two parameters: **state and action**, so the key in the value table is now a composite\n",
        "\n",
        "the optimal value of the action-state can be defined as:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJrTMeGan-L4"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuwhZopjn-ys"
      },
      "source": [
        "**Value Iteration with Q-function in Practice**\n",
        "\n",
        "The central data which will keep our tables and the functions, that we will be using in the training loop, are the same as the previous example of V-function. The main change is into the values table, a dictionary that now maps a state-action pair into the calculated value of this action.\n",
        "\n",
        "In the previous case, we kept the value of the state, so the key in the dictionary was just a state. Now we need to store values of the Q-function, which has two parameters: state and action, so the key in the value table is now a composite. This implies that another difference is in the *calc_action_value* function. We just don’t need it anymore, as our action values are stored in the value table.\n",
        "\n",
        "\n",
        "Finally, the most important change in the code is in the Agent’s *value_iteration()* method. Before, it was just a wrapper around the *calc_action_value()* call, which did the job of Bellman approximation. Now, as this function has gone and been replaced by a value table, we need to do this approximation in the *value_iteration()* method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f_Kwy7zoe75"
      },
      "source": [
        "**Frozen-Lake code for Q-function**\n",
        "\n",
        "Code is almost the same from the previous implementation: https://github.com/Jalapinho1/Deep-Reinforcement-Learning-Explained/blob/main/Value_Iteration_V_function.ipynb."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k1u6Dq3o_X4"
      },
      "source": [
        "```\n",
        "def value_iteration_for_Q(self):\n",
        "    for state in range(self.env.observation_space.n):\n",
        "        for action in range(self.env.action_space.n):\n",
        "            action_value = 0.0\n",
        "            target_counts = self.transits[(state, action)]\n",
        "            total = sum(target_counts.values())\n",
        "            for tgt_state, count in target_counts.items():\n",
        "                key = (state, action, tgt_state)\n",
        "                reward = self.rewards[key]\n",
        "                best_action = self.select_action(tgt_state)\n",
        "                val = reward + GAMMA * \\\n",
        "                      self.values[(tgt_state, best_action)]\n",
        "                action_value += (count / total) * val\n",
        "           self.values[(state, action)] = action_value\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfzRHN-6pPaN"
      },
      "source": [
        "The idea is that for a given state and action, it needs to calculate the action value using the information we collected by the function *play_n_random_steps* that plays N random steps from the Environment, populating the reward and transits tables with random experiences.\n",
        "\n",
        "However, in the previous implementation, we had the V-function stored in the value table, so we just took it from this table. We can’t do this anymore, so we have to call the *select_action* method, which will choose for us the best action with the largest Q-value, and then we take this Q-value as the value of the target state.\n",
        "\n",
        "In fact, this method is implemented differently, as it no longer calls the *calc_action_value* method but we just iterate over the actions and look up their values in our values table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONg5qq0yqKsF"
      },
      "source": [
        "```\n",
        "def select_action(self, state):\n",
        "    best_action, best_value = None, None\n",
        "    for action in range(self.env.action_space.n):\n",
        "        action_value = self.values[(state, action)]\n",
        "        if best_value is None or best_value < action_value:\n",
        "           best_value = action_value\n",
        "           best_action = action\n",
        "    return best_action\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSsO1U91qOy1"
      },
      "source": [
        "**Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IggESJmqRa5"
      },
      "source": [
        "import gym \n",
        "import collections\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "ENV_NAME = \"FrozenLake-v0\"\n",
        "#ENV_NAME = \"FrozenLake8x8-v0\"  \n",
        "GAMMA = 0.9\n",
        "TEST_EPISODES = 20\n",
        "REWARD_GOAL = 0.8\n",
        "N =100\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.env = gym.make(ENV_NAME)\n",
        "        self.state = self.env.reset()\n",
        "        self.rewards = collections.defaultdict(float)\n",
        "        self.transits = collections.defaultdict(\n",
        "            collections.Counter)\n",
        "        self.values = collections.defaultdict(float)\n",
        "\n",
        "    def play_n_random_steps(self, count):\n",
        "        for _ in range(count):\n",
        "            action = self.env.action_space.sample()\n",
        "            new_state, reward, is_done, _ = self.env.step(action)\n",
        "            self.rewards[(self.state, action, new_state)] = reward\n",
        "            self.transits[(self.state, action)][new_state] += 1\n",
        "            if is_done:\n",
        "                self.state = self.env.reset() \n",
        "            else: \n",
        "                self.state = new_state\n",
        "\n",
        "    def calc_action_value(self, state, action):\n",
        "        target_counts = self.transits[(state, action)]\n",
        "        total = sum(target_counts.values())\n",
        "        action_value = 0.0\n",
        "        for tgt_state, count in target_counts.items():\n",
        "            reward = self.rewards[(state, action, tgt_state)]\n",
        "            val = reward + GAMMA * self.values[tgt_state]\n",
        "            action_value += (count / total) * val\n",
        "        return action_value\n",
        "\n",
        "\n",
        "    def select_action(self, state):\n",
        "        best_action, best_value = None, None\n",
        "        for action in range(self.env.action_space.n):\n",
        "            action_value = self.values[(state, action)]\n",
        "            if best_value is None or best_value < action_value:\n",
        "                best_value = action_value\n",
        "                best_action = action\n",
        "        return best_action\n",
        "\n",
        "\n",
        "    def value_iteration_for_Q(self):\n",
        "        for state in range(self.env.observation_space.n):\n",
        "            for action in range(self.env.action_space.n):\n",
        "                action_value = 0.0\n",
        "                target_counts = self.transits[(state, action)]\n",
        "                total = sum(target_counts.values())\n",
        "                for tgt_state, count in target_counts.items():\n",
        "                    key = (state, action, tgt_state)\n",
        "                    reward = self.rewards[key]\n",
        "                    best_action = self.select_action(tgt_state)\n",
        "                    val = reward + GAMMA * \\\n",
        "                          self.values[(tgt_state, best_action)]\n",
        "                    action_value += (count / total) * val\n",
        "                self.values[(state, action)] = action_value"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMrr7MMSqWmg",
        "outputId": "b16fefab-11fe-46c0-f646-84f91bd753d8"
      },
      "source": [
        "# TRAINING\n",
        "test_env = gym.make(ENV_NAME)\n",
        "agent = Agent()\n",
        "writer = SummaryWriter()\n",
        "\n",
        "iter_no = 0\n",
        "best_reward = 0.0\n",
        " \n",
        "while best_reward < REWARD_GOAL:\n",
        "        \n",
        "        agent.play_n_random_steps(N)\n",
        "\n",
        "        agent.value_iteration_for_Q()\n",
        "\n",
        "        iter_no += 1\n",
        "        reward_test = 0.0\n",
        "        for _ in range(TEST_EPISODES):\n",
        "            total_reward = 0.0\n",
        "            state = test_env.reset()\n",
        "            while True:\n",
        "                action = agent.select_action(state)\n",
        "                new_state, new_reward, is_done, _ = test_env.step(action)\n",
        "                total_reward += new_reward\n",
        "                if is_done: break\n",
        "                state = new_state\n",
        "            reward_test += total_reward\n",
        "        reward_test /= TEST_EPISODES\n",
        "\n",
        "        writer.add_scalar(\"reward\", reward_test, iter_no)\n",
        "        if reward_test > best_reward:\n",
        "            print(\"Best reward updated %.2f at iteration %d \" % (reward_test ,iter_no) )\n",
        "            best_reward = reward_test\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best reward updated 0.05 at iteration 7 \n",
            "Best reward updated 0.10 at iteration 8 \n",
            "Best reward updated 0.65 at iteration 9 \n",
            "Best reward updated 0.80 at iteration 10 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ufv-xsQFqd71",
        "outputId": "26c8666f-0b34-4864-dfbb-79869b874470"
      },
      "source": [
        "new_test_env = gym.make(ENV_NAME) \n",
        "state = new_test_env.reset()\n",
        "new_test_env.render()\n",
        "is_done = False\n",
        "iter_no = 0\n",
        "while not is_done:\n",
        "     print (state)\n",
        "     action = agent.select_action(state)\n",
        "     new_state, reward, is_done, _ = new_test_env.step(action)\n",
        "     test_env.render()\n",
        "     state = new_state\n",
        "     iter_no +=1\n",
        "print(\"reward =    \", reward)\n",
        "print(\"iterations =\", iter_no)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "8\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "9\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "8\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "0\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "8\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "8\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "8\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "4\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "8\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "9\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "13\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "13\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "13\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "13\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "14\n",
            "  (Down)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "reward =     1.0\n",
            "iterations = 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_CHc0EnqgSX"
      },
      "source": [
        "%load_ext tensorboard\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNErfs6oqxaC"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqDZcgM-qqBr"
      },
      "source": [
        "**CONCLUSIONS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q91qAcAHqskg"
      },
      "source": [
        "Q-values are much more convenient in practice, as for the agent, it’s much simpler to make decisions about actions based on Q-values than on V-values. In the case of Q-values, to choose the action based on the state, the agent just needs to calculate Q-value for all available actions using the current state and choose the action with the largest Q-value.\n",
        "\n",
        "To do the same using values of the states, **V-value**, the agent **needs to know not only values but also probabilities for transitions**. In practice, we **rarely** know them in advance, so the agent needs to estimate transition probabilities for every action and state pair.\n",
        "\n",
        "In the Value Iteration method for V-function, this dependency on probability adds an extra burden for the agent. That said, it is important to know this method because they are an essential part of advanced methods.\n"
      ]
    }
  ]
}